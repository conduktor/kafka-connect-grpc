{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Kafka Connect gRPC Source Connector","text":"<p>Stream real-time data from gRPC server streaming endpoints directly into Apache Kafka with automatic reconnection, TLS/mTLS support, and comprehensive monitoring.</p> <p>Get Started View on GitHub</p>"},{"location":"#features","title":"Features","text":""},{"location":"#server-streaming-support","title":"Server Streaming Support","text":"<p>Connect to any gRPC server streaming RPC and continuously receive messages with minimal latency and efficient resource usage.</p>"},{"location":"#dynamic-proto-handling","title":"Dynamic Proto Handling","text":"<p>Use Protocol Buffer descriptors for flexible message handling without requiring compiled proto classes - just provide your .desc file.</p>"},{"location":"#tlsmtls-support","title":"TLS/mTLS Support","text":"<p>Full TLS and mutual TLS support with configurable certificates for secure connections to production gRPC services.</p>"},{"location":"#automatic-reconnection","title":"Automatic Reconnection","text":"<p>Built-in reconnection logic with exponential backoff ensures resilient connections even when gRPC servers restart or network issues occur.</p>"},{"location":"#built-in-monitoring","title":"Built-in Monitoring","text":"<p>Comprehensive JMX metrics, detailed logging with structured events, and integration with Prometheus/Grafana for production observability.</p>"},{"location":"#offset-management","title":"Offset Management","text":"<p>Sequence-based offset tracking for reliable message delivery, enabling exactly-once semantics and gap detection across reconnections.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<p>Stream data from a gRPC service into Kafka:</p> Connector ConfigurationDeploy ConnectorConsume Messages <pre><code>{\n  \"name\": \"grpc-streaming-connector\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.grpc.GrpcSourceConnector\",\n    \"tasks.max\": \"1\",\n    \"grpc.server.host\": \"localhost\",\n    \"grpc.server.port\": \"9090\",\n    \"grpc.service.name\": \"com.example.EventService\",\n    \"grpc.method.name\": \"StreamEvents\",\n    \"grpc.request.message\": \"{\\\"filter\\\":\\\"active\\\"}\",\n    \"kafka.topic\": \"grpc-events\"\n  }\n}\n</code></pre> <pre><code>curl -X POST http://localhost:8083/connectors \\\n  -H \"Content-Type: application/json\" \\\n  -d @grpc-connector.json\n</code></pre> <pre><code>kafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic grpc-events \\\n  --from-beginning\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":"<p>The connector is ideal for streaming real-time data from:</p> <ul> <li>Microservices Communication - Stream events between microservices using gRPC server streaming</li> <li>Event Streaming Platforms - Ingest data from gRPC-based event streaming systems</li> <li>Real-time Data Pipelines - Connect gRPC data sources to Kafka-based data pipelines</li> <li>Cloud-Native Applications - Integrate with Kubernetes-native services exposing gRPC APIs</li> <li>IoT &amp; Telemetry - Stream sensor data and metrics from gRPC-enabled devices</li> <li>Financial Services - Ingest market data, transaction streams, and risk feeds via gRPC</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>graph LR\n    A[gRPC Server&lt;br/&gt;Streaming RPC] --&gt;|Server Stream| B[Message Queue]\n    B --&gt;|Poll| C[Kafka Connect Task]\n    C --&gt;|Produce| D[Kafka Topic]\n\n    E[Proto Descriptor] -.-&gt;|Define Schema| A\n    F[Offset Storage] -.-&gt;|Track Sequence| C\n\n    style A fill:#3b82f6\n    style B fill:#f59e0b\n    style C fill:#10b981\n    style D fill:#ef4444\n    style E fill:#8b5cf6\n    style F fill:#06b6d4</code></pre> <p>The connector uses gRPC's ManagedChannel for reliable connections, maintains an in-memory queue for buffering, and integrates seamlessly with Kafka Connect's task framework. Protocol Buffer descriptors enable dynamic message handling without code generation.</p>"},{"location":"#why-this-connector","title":"Why This Connector?","text":"Feature Kafka Connect gRPC Custom Consumer REST Polling Real-time streaming \u2705 Server streaming \u2705 Server streaming \u274c Polling delays Kafka integration \u2705 Native \u26a0\ufe0f Manual \u26a0\ufe0f Manual Reconnection logic \u2705 Built-in \u26a0\ufe0f Custom code \u26a0\ufe0f Custom code Monitoring \u2705 JMX/Prometheus \u26a0\ufe0f Custom \u26a0\ufe0f Custom Deployment \u2705 Kafka Connect \u274c Separate service \u274c Separate service TLS/mTLS \u2705 Built-in \u26a0\ufe0f Manual setup \u26a0\ufe0f Manual setup Offset tracking \u2705 Sequence-based \u26a0\ufe0f DIY \u274c Not applicable"},{"location":"#performance","title":"Performance","text":"<ul> <li>Throughput: Handles 10,000+ messages/second on standard hardware</li> <li>Latency: &lt; 5ms from gRPC receipt to Kafka produce</li> <li>Reliability: Automatic reconnection with exponential backoff</li> <li>Scalability: Configurable queue size for traffic bursts</li> <li>Message Size: Supports up to 4MB messages (configurable)</li> </ul>"},{"location":"#operational-features","title":"Operational Features","text":"<p>Includes comprehensive operational tooling:</p> <ul> <li>Detailed error handling and structured logging with MDC context</li> <li>JMX metrics for Prometheus/Grafana integration</li> <li>Automatic reconnection with exponential backoff</li> <li>Configurable message buffering with backpressure handling</li> <li>Sequence-based offset tracking for exactly-once semantics</li> <li>Gap detection for identifying potential message loss</li> <li>Extensive troubleshooting documentation and runbook</li> </ul>"},{"location":"#important-offset-management","title":"Important: Offset Management","text":"<p>Sequence-Based Offset Tracking</p> <p>This connector implements sequence-based offset tracking:</p> <ul> <li>Session ID: Unique identifier for each connection lifecycle</li> <li>Sequence Numbers: Monotonically increasing counter for each message</li> <li>Gap Detection: Automatically detects missing sequence numbers</li> <li>Resume Support: Can resume from last committed offset after restart</li> </ul> <p>This enables reliable message delivery and helps identify potential data loss scenarios. However, the connector cannot replay messages from the gRPC server - it can only detect gaps in the sequence.</p>"},{"location":"#development-testing","title":"Development &amp; Testing","text":""},{"location":"#building-from-source","title":"Building from Source","text":"<pre><code>git clone https://github.com/conduktor/kafka-connect-grpc.git\ncd kafka-connect-grpc\nmvn clean package\n</code></pre>"},{"location":"#running-tests","title":"Running Tests","text":"<pre><code># Unit tests\nmvn test\n\n# Integration tests (requires Docker)\nmvn verify\n</code></pre> <p>The test suite includes:</p> <ul> <li>Unit Tests: Configuration validation, connector lifecycle, task management</li> <li>Integration Tests: gRPC client behavior, TLS configuration, proto descriptor handling</li> <li>System Integration Tests (<code>GrpcConnectorSystemIT</code>): Full end-to-end testing with Testcontainers that spins up Kafka + Kafka Connect containers</li> </ul>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>GitHub Issues: Report bugs and request features</li> <li>Slack Community: Join Conduktor Slack</li> <li>Documentation: Full reference guide</li> </ul>"},{"location":"#license","title":"License","text":"<p>Apache License 2.0 - see LICENSE for details.</p>"},{"location":"#ready-to-get-started","title":"Ready to Get Started?","text":"<p>Getting Started Guide View on GitHub See FAQ</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to the Kafka Connect gRPC Source Connector will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#planned-features","title":"Planned Features","text":"<ul> <li> Support for custom message key extraction</li> <li> Dead letter queue support for failed messages</li> <li> Enhanced compression support for Kafka producer</li> <li> Metrics dashboard templates (Grafana)</li> <li> Helm chart for Kubernetes deployments</li> <li> Support for gRPC reflection (no descriptor file needed)</li> </ul>"},{"location":"changelog/#100-2025-12-17","title":"1.0.0 - 2025-12-17","text":""},{"location":"changelog/#added","title":"Added","text":""},{"location":"changelog/#core-features","title":"Core Features","text":"<ul> <li>Initial release of Kafka Connect gRPC Source Connector</li> <li>Support for gRPC server streaming RPCs</li> <li>Dynamic message handling via Protocol Buffer descriptors</li> <li>Automatic reconnection with exponential backoff</li> <li>Sequence-based offset tracking for reliable delivery</li> <li>Comprehensive logging with structured events</li> <li>JMX metrics for production monitoring</li> </ul>"},{"location":"changelog/#grpc-features","title":"gRPC Features","text":"<ul> <li>TLS support for secure connections</li> <li>Mutual TLS (mTLS) for client authentication</li> <li>Custom metadata/headers support</li> <li>Configurable keepalive settings</li> <li>Adjustable message size limits (default 4MB)</li> <li>Request message support (JSON to Protobuf conversion)</li> </ul>"},{"location":"changelog/#configuration","title":"Configuration","text":"<ul> <li>Required parameters:</li> <li><code>grpc.server.host</code> - gRPC server hostname</li> <li><code>grpc.server.port</code> - gRPC server port</li> <li><code>grpc.service.name</code> - Fully qualified service name</li> <li><code>grpc.method.name</code> - Server streaming method name</li> <li><code>kafka.topic</code> - Target Kafka topic</li> <li>Optional parameters:</li> <li><code>grpc.request.message</code> - JSON request message</li> <li><code>grpc.proto.descriptor</code> - Path to .desc file or base64-encoded descriptor</li> <li><code>grpc.tls.enabled</code> - Enable TLS</li> <li><code>grpc.tls.ca.cert</code> - CA certificate path</li> <li><code>grpc.tls.client.cert</code> - Client certificate for mTLS</li> <li><code>grpc.tls.client.key</code> - Client private key for mTLS</li> <li><code>grpc.metadata</code> - Custom metadata/headers</li> <li><code>grpc.reconnect.enabled</code> - Enable auto-reconnection (default: true)</li> <li><code>grpc.reconnect.interval.ms</code> - Reconnection interval (default: 5000ms)</li> <li><code>grpc.reconnect.max.attempts</code> - Max retry attempts (default: -1, infinite)</li> <li><code>grpc.reconnect.backoff.max.ms</code> - Max backoff delay (default: 60000ms)</li> <li><code>grpc.message.queue.size</code> - Queue size (default: 10000)</li> <li><code>grpc.connection.timeout.ms</code> - Connection timeout (default: 30000ms)</li> <li><code>grpc.keepalive.time.ms</code> - Keepalive interval (default: 30000ms)</li> <li><code>grpc.keepalive.timeout.ms</code> - Keepalive timeout (default: 10000ms)</li> <li><code>grpc.max.inbound.message.size</code> - Max message size (default: 4MB)</li> </ul>"},{"location":"changelog/#monitoring-operations","title":"Monitoring &amp; Operations","text":"<ul> <li>JMX metrics exposure via Kafka Connect framework:</li> <li><code>MessagesReceived</code> - Total messages from gRPC</li> <li><code>MessagesDropped</code> - Messages dropped due to queue overflow</li> <li><code>RecordsProduced</code> - Total records written to Kafka</li> <li><code>QueueSize</code> - Current queue size</li> <li><code>QueueUtilizationPercent</code> - Queue utilization percentage</li> <li><code>IsConnected</code> - Connection status</li> <li><code>MillisSinceLastMessage</code> - Time since last message</li> <li><code>UptimeMillis</code> - Connection uptime</li> <li><code>TotalReconnects</code> - Total reconnection attempts</li> <li><code>LagCount</code> - Messages received but not produced</li> <li><code>DropRate</code> - Message drop rate percentage</li> <li>Structured logging with MDC context:</li> <li><code>event=task_starting</code> - Task initialization</li> <li><code>event=session_initialized</code> - New session started</li> <li><code>event=streaming_started</code> - gRPC stream active</li> <li><code>event=message_received</code> - Message received</li> <li><code>event=sequence_gap</code> - Gap in sequence detected</li> <li><code>event=task_metrics</code> - Periodic metrics log</li> <li>Integration with Prometheus via JMX Exporter</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>Comprehensive README with installation and usage</li> <li>Quick start guide with multiple examples:</li> <li>Basic plaintext gRPC connection</li> <li>TLS-secured connection</li> <li>Mutual TLS (mTLS) configuration</li> <li>Custom metadata/headers</li> <li>Request message with proto descriptor</li> <li>Detailed troubleshooting section</li> <li>Architecture documentation with diagrams</li> <li>Production deployment recommendations</li> <li>MkDocs-based documentation website</li> </ul>"},{"location":"changelog/#testing","title":"Testing","text":"<ul> <li>Unit tests for connector and configuration</li> <li>Integration tests with mock gRPC server</li> <li>Configuration validation tests</li> <li>Test coverage for all major components</li> </ul>"},{"location":"changelog/#dependencies","title":"Dependencies","text":"<ul> <li>Apache Kafka Connect API 3.9.0</li> <li>gRPC Java 1.60.0</li> <li>Protocol Buffers 3.25.0</li> <li>SLF4J logging API 1.7.36</li> <li>JUnit 5.9.2 (testing)</li> <li>Mockito 5.2.0 (testing)</li> </ul>"},{"location":"changelog/#technical-details","title":"Technical Details","text":""},{"location":"changelog/#architecture","title":"Architecture","text":"<ul> <li>GrpcSourceConnector: Main connector class managing configuration and task lifecycle</li> <li>GrpcSourceTask: Task implementation handling gRPC streaming and message polling</li> <li>GrpcClient: Manages gRPC channel, StreamObserver, and reconnection logic</li> <li>GrpcSourceConnectorConfig: Configuration definition with validation</li> <li>GrpcMetrics: JMX metrics bean for monitoring</li> </ul>"},{"location":"changelog/#data-flow","title":"Data Flow","text":"<pre><code>gRPC Server (StreamObserver) \u2192 LinkedBlockingDeque Queue \u2192\nSourceTask.poll() \u2192 SourceRecord \u2192 Kafka Topic\n</code></pre>"},{"location":"changelog/#offset-management","title":"Offset Management","text":"<ul> <li>Session-based tracking with unique session ID per connection</li> <li>Sequence numbers for each message</li> <li>Gap detection for identifying lost messages</li> <li>Offset format: <code>{\"sessionId\":\"uuid\",\"sequence\":123}</code></li> </ul>"},{"location":"changelog/#limitations-documented","title":"Limitations Documented","text":"<ul> <li>Single task per connector (gRPC streaming constraint)</li> <li>Server streaming only (no unary, client streaming, or bidirectional)</li> <li>Cannot replay from gRPC server (streaming limitation)</li> <li>At-least-once semantics (with gap detection)</li> <li>In-memory queue data lost on shutdown</li> </ul>"},{"location":"changelog/#known-issues","title":"Known Issues","text":"<ul> <li>None reported in initial release</li> </ul>"},{"location":"changelog/#breaking-changes","title":"Breaking Changes","text":"<p>N/A - Initial release</p>"},{"location":"changelog/#version-history-format","title":"Version History Format","text":""},{"location":"changelog/#xyz-yyyy-mm-dd","title":"[X.Y.Z] - YYYY-MM-DD","text":""},{"location":"changelog/#added_1","title":"Added","text":"<p>Features or capabilities that were added in this release.</p>"},{"location":"changelog/#changed","title":"Changed","text":"<p>Changes in existing functionality or behavior.</p>"},{"location":"changelog/#deprecated","title":"Deprecated","text":"<p>Features that will be removed in future releases.</p>"},{"location":"changelog/#removed","title":"Removed","text":"<p>Features that were removed in this release.</p>"},{"location":"changelog/#fixed","title":"Fixed","text":"<p>Bug fixes and error corrections.</p>"},{"location":"changelog/#security","title":"Security","text":"<p>Security vulnerability fixes and improvements.</p>"},{"location":"changelog/#upgrade-guide","title":"Upgrade Guide","text":""},{"location":"changelog/#from-pre-release-to-100","title":"From Pre-Release to 1.0.0","text":"<p>This is the initial stable release. No migration required.</p>"},{"location":"changelog/#future-upgrades","title":"Future Upgrades","text":"<p>Upgrade instructions will be provided here for future releases.</p>"},{"location":"changelog/#support-policy","title":"Support Policy","text":""},{"location":"changelog/#version-support","title":"Version Support","text":"<ul> <li>Latest stable version: Full support with bug fixes and security updates</li> <li>Previous minor version: Security fixes only</li> <li>Older versions: Community support via GitHub Issues</li> </ul>"},{"location":"changelog/#compatibility-matrix","title":"Compatibility Matrix","text":"Connector Version Min Kafka Version Max Kafka Version Java Version gRPC Java Version 1.0.0 3.9.0 Latest 11+ 1.60.0"},{"location":"changelog/#release-notes-archive","title":"Release Notes Archive","text":""},{"location":"changelog/#release-highlights","title":"Release Highlights","text":""},{"location":"changelog/#100-initial-stable-release-2025-12-17","title":"1.0.0 - Initial Stable Release (2025-12-17)","text":"<p>Production-Ready gRPC Streaming to Kafka</p> <p>The Kafka Connect gRPC Source Connector is now production-ready with comprehensive features for streaming real-time data from gRPC server streaming endpoints into Apache Kafka.</p> <p>Key Capabilities: - Stream from any gRPC server streaming RPC - Dynamic message handling via Protocol Buffer descriptors - Full TLS and mutual TLS support - Automatic reconnection with exponential backoff - Sequence-based offset tracking</p> <p>Production Features: - Comprehensive JMX metrics - Structured logging with MDC context - Built-in monitoring and alerting support - Prometheus/Grafana integration</p> <p>Getting Started: <pre><code>mvn clean package\ncp target/kafka-connect-grpc-1.0.0-jar-with-dependencies.jar \\\n  $KAFKA_HOME/plugins/kafka-connect-grpc/\n</code></pre></p> <p>Example Configuration: <pre><code>{\n  \"name\": \"grpc-streaming-connector\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.grpc.GrpcSourceConnector\",\n    \"grpc.server.host\": \"localhost\",\n    \"grpc.server.port\": \"9090\",\n    \"grpc.service.name\": \"com.example.EventService\",\n    \"grpc.method.name\": \"StreamEvents\",\n    \"kafka.topic\": \"grpc-events\"\n  }\n}\n</code></pre></p> <p>Important Notes: - Server streaming only (not unary or bidirectional) - Sequence-based offset tracking with gap detection - At-least-once semantics - In-memory queue data lost on shutdown</p>"},{"location":"changelog/#contributing-to-changelog","title":"Contributing to Changelog","text":"<p>When submitting a PR, please update the <code>[Unreleased]</code> section with your changes under the appropriate category (Added, Changed, Fixed, etc.).</p> <p>Format: <pre><code>### Category\n- Brief description of change ([#PR_NUMBER](link))\n</code></pre></p> <p>Example: <pre><code>### Added\n- Support for gRPC reflection API ([#42](https://github.com/conduktor/kafka-connect-grpc/pull/42))\n\n### Fixed\n- Memory leak in queue overflow scenario ([#38](https://github.com/conduktor/kafka-connect-grpc/pull/38))\n</code></pre></p>"},{"location":"changelog/#links","title":"Links","text":"<ul> <li>GitHub Repository</li> <li>Issue Tracker</li> <li>Documentation</li> <li>Conduktor Website</li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Common questions and answers about the Kafka Connect gRPC Source Connector.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-this-connector-used-for","title":"What is this connector used for?","text":"<p>The Kafka Connect gRPC connector streams real-time data from gRPC server streaming endpoints into Kafka topics. It's ideal for:</p> <ul> <li>Microservices communication using gRPC</li> <li>Event streaming from gRPC-based platforms</li> <li>Real-time data pipelines with gRPC sources</li> <li>Cloud-native applications exposing gRPC APIs</li> <li>IoT and telemetry data from gRPC-enabled devices</li> <li>Financial services data feeds via gRPC</li> </ul>"},{"location":"faq/#how-does-it-differ-from-the-websocket-connector","title":"How does it differ from the WebSocket connector?","text":"Feature gRPC Connector WebSocket Connector Protocol HTTP/2 + Protocol Buffers WebSocket Schema Strong typing via Protobuf String messages only Streaming Server streaming RPC WebSocket push TLS/mTLS Built-in support TLS only Offset Tracking Sequence-based None Message Format Binary (Protobuf) Text (JSON typically) Use Cases Microservices, typed APIs Exchange feeds, IoT"},{"location":"faq/#what-grpc-patterns-are-supported","title":"What gRPC patterns are supported?","text":"<p>Supported: - \u2705 Server streaming (one request, stream of responses)</p> <p>Not Supported: - \u274c Unary (request-response) - \u274c Client streaming (stream of requests, one response) - \u274c Bidirectional streaming (stream both ways)</p> <p>Only server streaming is compatible with Kafka Connect's source connector model.</p>"},{"location":"faq/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"faq/#do-i-need-to-build-from-source","title":"Do I need to build from source?","text":"<p>No. Pre-built JARs are available from GitHub Releases:</p> <pre><code># Download the latest release\nwget https://github.com/conduktor/kafka-connect-grpc/releases/download/v1.0.0/kafka-connect-grpc-1.0.0-jar-with-dependencies.jar\n\n# Copy to plugin directory\ncp kafka-connect-grpc-1.0.0-jar-with-dependencies.jar $KAFKA_HOME/plugins/kafka-connect-grpc/\n</code></pre> <p>Building from source is only needed for development or custom modifications.</p>"},{"location":"faq/#which-kafka-version-do-i-need","title":"Which Kafka version do I need?","text":"<p>Minimum: Kafka 3.9.0 Recommended: Latest stable Kafka version</p> <p>The connector uses Kafka Connect API features available in 3.9.0+.</p>"},{"location":"faq/#do-i-need-protoc-installed","title":"Do I need protoc installed?","text":"<p>Yes, if you need to generate Protocol Buffer descriptor files (.desc).</p> <pre><code># Install protoc\nbrew install protobuf  # macOS\nsudo apt install protobuf-compiler  # Ubuntu/Debian\n\n# Generate descriptor\nprotoc --descriptor_set_out=service.desc \\\n  --include_imports \\\n  your_service.proto\n</code></pre> <p>The descriptor file is required for dynamic message handling.</p>"},{"location":"faq/#can-i-use-this-with-confluent-platform","title":"Can I use this with Confluent Platform?","text":"<p>Yes, the connector works with:</p> <ul> <li>Apache Kafka (open source)</li> <li>Confluent Platform</li> <li>Amazon MSK (Managed Streaming for Kafka)</li> <li>Azure Event Hubs for Kafka</li> <li>Any Kafka-compatible platform supporting Connect API</li> </ul>"},{"location":"faq/#configuration","title":"Configuration","text":""},{"location":"faq/#whats-the-minimum-configuration","title":"What's the minimum configuration?","text":"<p>Five required parameters:</p> <pre><code>{\n  \"connector.class\": \"io.conduktor.connect.grpc.GrpcSourceConnector\",\n  \"grpc.server.host\": \"localhost\",\n  \"grpc.server.port\": \"9090\",\n  \"grpc.service.name\": \"com.example.MyService\",\n  \"grpc.method.name\": \"StreamData\",\n  \"kafka.topic\": \"grpc-messages\"\n}\n</code></pre>"},{"location":"faq/#how-do-i-configure-tlsmtls","title":"How do I configure TLS/mTLS?","text":"<p>TLS (server verification only): <pre><code>{\n  \"grpc.tls.enabled\": \"true\",\n  \"grpc.tls.ca.cert\": \"/path/to/ca.crt\"\n}\n</code></pre></p> <p>mTLS (mutual authentication): <pre><code>{\n  \"grpc.tls.enabled\": \"true\",\n  \"grpc.tls.ca.cert\": \"/path/to/ca.crt\",\n  \"grpc.tls.client.cert\": \"/path/to/client.crt\",\n  \"grpc.tls.client.key\": \"/path/to/client.key\"\n}\n</code></pre></p>"},{"location":"faq/#how-do-i-add-custom-metadataheaders","title":"How do I add custom metadata/headers?","text":"<p>Option 1: Comma-separated format <pre><code>{\n  \"grpc.metadata\": \"authorization:Bearer token123,x-api-key:key456\"\n}\n</code></pre></p> <p>Option 2: Individual entries <pre><code>{\n  \"grpc.metadata.authorization\": \"Bearer token123\",\n  \"grpc.metadata.x-api-key\": \"key456\"\n}\n</code></pre></p>"},{"location":"faq/#how-do-i-send-a-request-message","title":"How do I send a request message?","text":"<p>Use <code>grpc.request.message</code> with JSON format:</p> <pre><code>{\n  \"grpc.request.message\": \"{\\\"filter\\\":\\\"active\\\",\\\"limit\\\":100}\",\n  \"grpc.proto.descriptor\": \"/path/to/service.desc\"\n}\n</code></pre> <p>The JSON is converted to Protobuf using the descriptor file.</p>"},{"location":"faq/#can-i-connect-to-multiple-grpc-endpoints","title":"Can I connect to multiple gRPC endpoints?","text":"<p>No, each connector instance connects to one gRPC endpoint. To stream from multiple endpoints:</p> <ol> <li>Create separate connector instances</li> <li>Use different connector names</li> <li>Route to the same or different Kafka topics</li> </ol> <p>Example: <pre><code># Connector 1: Service A\ncurl -X POST http://localhost:8083/connectors \\\n  -d '{\"name\":\"grpc-service-a\", \"config\":{...}}'\n\n# Connector 2: Service B\ncurl -X POST http://localhost:8083/connectors \\\n  -d '{\"name\":\"grpc-service-b\", \"config\":{...}}'\n</code></pre></p>"},{"location":"faq/#proto-descriptors","title":"Proto Descriptors","text":""},{"location":"faq/#what-is-a-proto-descriptor-file","title":"What is a proto descriptor file?","text":"<p>A compiled Protocol Buffer schema containing all message and service definitions. It's used for dynamic message handling without code generation.</p>"},{"location":"faq/#how-do-i-generate-a-descriptor-file","title":"How do I generate a descriptor file?","text":"<pre><code>protoc --descriptor_set_out=service.desc \\\n  --include_imports \\\n  your_service.proto\n</code></pre> <p>Important: Always use <code>--include_imports</code> to include dependencies.</p>"},{"location":"faq/#can-i-use-base64-encoded-descriptors","title":"Can I use base64-encoded descriptors?","text":"<p>Yes, you can base64-encode the descriptor and provide it inline:</p> <pre><code># Encode descriptor\nbase64 service.desc &gt; service.desc.b64\n\n# Use in configuration\n{\n  \"grpc.proto.descriptor\": \"$(cat service.desc.b64)\"\n}\n</code></pre>"},{"location":"faq/#what-if-my-proto-imports-other-files","title":"What if my proto imports other files?","text":"<p>Use <code>--include_imports</code> when generating the descriptor:</p> <pre><code>protoc --descriptor_set_out=service.desc \\\n  --include_imports \\\n  --proto_path=. \\\n  --proto_path=./vendor \\\n  your_service.proto\n</code></pre> <p>This includes all imported message definitions in the descriptor.</p>"},{"location":"faq/#data-reliability","title":"Data &amp; Reliability","text":""},{"location":"faq/#what-delivery-guarantees-does-this-connector-provide","title":"What delivery guarantees does this connector provide?","text":"<p>The connector provides at-least-once delivery semantics with sequence-based offset tracking:</p> <ul> <li>Messages are tracked by sequence number</li> <li>Offsets are committed to Kafka Connect</li> <li>Gaps in sequence numbers are detected and logged</li> <li>Cannot replay from gRPC server (server streaming limitation)</li> </ul>"},{"location":"faq/#what-happens-if-the-connector-crashes","title":"What happens if the connector crashes?","text":"<ol> <li>In-memory queue: Messages in queue are lost</li> <li>Offset tracking: Last committed offset is preserved</li> <li>Reconnection: Connector reconnects and requests new stream</li> <li>Gap detection: Sequence gaps are logged as warnings</li> </ol> <p>The connector cannot replay lost messages from the gRPC server.</p>"},{"location":"faq/#can-i-replay-historical-data","title":"Can I replay historical data?","text":"<p>No. gRPC server streaming limitations:</p> <ul> <li>Server doesn't store message history</li> <li>Cannot \"rewind\" to previous position</li> <li>Each connection gets a new stream starting from current state</li> </ul> <p>For historical data, use the gRPC server's unary RPC methods (if available) or another mechanism.</p>"},{"location":"faq/#what-data-format-is-produced-to-kafka","title":"What data format is produced to Kafka?","text":"<p>Messages are produced as JSON strings (converted from Protobuf):</p> <pre><code>{\n  \"topic\": \"grpc-messages\",\n  \"partition\": 0,\n  \"offset\": 12345,\n  \"key\": null,\n  \"value\": \"{\\\"field1\\\":\\\"value1\\\",\\\"field2\\\":123}\"\n}\n</code></pre> <p>For structured processing, use Kafka Streams or ksqlDB to parse JSON downstream.</p>"},{"location":"faq/#how-are-offsets-tracked","title":"How are offsets tracked?","text":"<p>The connector uses sequence-based offset tracking:</p> <ul> <li>Session ID: Unique per connection (UUID)</li> <li>Sequence Number: Monotonically increasing counter</li> <li>Offset Format: <code>{\"sessionId\":\"abc123\",\"sequence\":1000}</code></li> </ul> <p>This enables gap detection and tracking across reconnections.</p>"},{"location":"faq/#operations","title":"Operations","text":""},{"location":"faq/#how-do-i-monitor-the-connector","title":"How do I monitor the connector?","text":"<p>Three monitoring approaches:</p> <ol> <li> <p>JMX Metrics (recommended):    <pre><code># View metrics via JMX\njconsole localhost:9999\n</code></pre></p> </li> <li> <p>Structured Logging:    <pre><code>tail -f $KAFKA_HOME/logs/connect.log | grep \"event=\"\n</code></pre></p> </li> <li> <p>Kafka Connect REST API:    <pre><code>curl http://localhost:8083/connectors/grpc-connector/status\n</code></pre></p> </li> </ol> <p>See Configuration for monitoring setup.</p>"},{"location":"faq/#what-metrics-should-i-alert-on","title":"What metrics should I alert on?","text":"<p>Critical alerts:</p> <ul> <li>Connector down - <code>connector.state != RUNNING</code></li> <li>Not connected - <code>IsConnected = false</code> for &gt; 5 minutes</li> <li>No messages - <code>MessagesReceived</code> not increasing</li> <li>Queue overflow - <code>QueueUtilizationPercent &gt; 80%</code></li> <li>High reconnection rate - <code>TotalReconnects</code> increasing rapidly</li> </ul>"},{"location":"faq/#how-do-i-troubleshoot-connection-failures","title":"How do I troubleshoot connection failures?","text":"<ol> <li> <p>Test gRPC endpoint:    <pre><code>grpcurl -plaintext localhost:9090 list\ngrpcurl -plaintext localhost:9090 com.example.MyService/StreamData\n</code></pre></p> </li> <li> <p>Check TLS configuration:    <pre><code>openssl s_client -connect grpc-server:443\n</code></pre></p> </li> <li> <p>Review connector logs:    <pre><code>grep \"event=connection_failed\" $KAFKA_HOME/logs/connect.log\n</code></pre></p> </li> <li> <p>Verify proto descriptor:    <pre><code>grpcurl -protoset service.desc list\n</code></pre></p> </li> </ol>"},{"location":"faq/#how-do-i-update-connector-configuration","title":"How do I update connector configuration?","text":"<p>For running connectors:</p> <pre><code>curl -X PUT http://localhost:8083/connectors/grpc-connector/config \\\n  -H \"Content-Type: application/json\" \\\n  -d @updated-config.json\n</code></pre> <p>The connector will restart automatically with new configuration.</p> <p>Note: Some changes require full restart (TLS, server host/port, service/method names).</p>"},{"location":"faq/#can-i-pause-and-resume-the-connector","title":"Can I pause and resume the connector?","text":"<p>Yes, use the Kafka Connect REST API:</p> <p>Pause: <pre><code>curl -X PUT http://localhost:8083/connectors/grpc-connector/pause\n</code></pre></p> <p>Resume: <pre><code>curl -X PUT http://localhost:8083/connectors/grpc-connector/resume\n</code></pre></p> <p>Warning: Pausing closes the gRPC connection. Messages sent during pause are lost.</p>"},{"location":"faq/#performance","title":"Performance","text":""},{"location":"faq/#what-throughput-can-i-expect","title":"What throughput can I expect?","text":"<p>Typical performance on standard hardware (4 CPU, 8 GB RAM):</p> <ul> <li>Message rate: 10,000+ messages/second</li> <li>Latency: &lt; 5ms from gRPC receipt to Kafka produce</li> <li>Queue capacity: Configurable (default: 10,000 messages)</li> </ul> <p>Actual throughput depends on: - Message size - Kafka broker performance - Network latency - gRPC server throughput</p>"},{"location":"faq/#how-many-tasks-can-i-run-per-connector","title":"How many tasks can I run per connector?","text":"<p>Always 1 task per connector.</p> <p>gRPC server streaming connections are single-threaded by design. Each connector maintains one gRPC stream.</p> <p>To parallelize: - Create multiple connector instances - Each connects to different service/method or uses different request filters</p>"},{"location":"faq/#whats-the-memory-footprint","title":"What's the memory footprint?","text":"<p>Memory usage depends on queue size and message size:</p> <p>Formula: <pre><code>Memory \u2248 queue_size \u00d7 avg_message_size \u00d7 2\n</code></pre></p> <p>Example: - Queue size: 10,000 messages - Average message: 2 KB (Protobuf) - Memory: ~40 MB (with overhead)</p> <p>Recommendation: - Development: 512 MB heap - Production: 2 GB heap</p>"},{"location":"faq/#how-do-i-optimize-throughput","title":"How do I optimize throughput?","text":"<ol> <li> <p>Increase queue size (handle bursts):    <pre><code>grpc.message.queue.size=50000\n</code></pre></p> </li> <li> <p>Increase message size limit (if needed):    <pre><code>grpc.max.inbound.message.size=16777216\n</code></pre></p> </li> <li> <p>Optimize Kafka producer (in <code>connect-distributed.properties</code>):    <pre><code>producer.linger.ms=10\nproducer.batch.size=32768\nproducer.compression.type=lz4\n</code></pre></p> </li> <li> <p>Tune keepalive (reduce overhead):    <pre><code>grpc.keepalive.time.ms=60000\n</code></pre></p> </li> </ol>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#why-isnt-my-connector-appearing-in-the-plugin-list","title":"Why isn't my connector appearing in the plugin list?","text":"<p>Check:</p> <ol> <li>JAR is in the correct plugin directory</li> <li><code>plugin.path</code> is configured in <code>connect-distributed.properties</code></li> <li>Kafka Connect was restarted after installation</li> <li>All dependencies are present (should use uber JAR)</li> </ol> <p>Verify: <pre><code>ls -lh $KAFKA_HOME/plugins/kafka-connect-grpc/\ncurl http://localhost:8083/connector-plugins | jq\n</code></pre></p>"},{"location":"faq/#why-do-i-get-unavailable-io-exception","title":"Why do I get \"UNAVAILABLE: io exception\"?","text":"<p>Cause: gRPC server not reachable.</p> <p>Solution: <pre><code># Test connectivity\ntelnet grpc-server 9090\n\n# Test with grpcurl\ngrpcurl -plaintext grpc-server:9090 list\n\n# Check connector logs\ngrep \"event=connection_failed\" $KAFKA_HOME/logs/connect.log\n</code></pre></p>"},{"location":"faq/#why-do-i-get-service-not-found-in-descriptor","title":"Why do I get \"Service not found in descriptor\"?","text":"<p>Cause: Service name doesn't match proto definition.</p> <p>Solution: <pre><code># List services in descriptor\ngrpcurl -protoset service.desc list\n\n# Verify exact service name (case-sensitive)\ngrpcurl -protoset service.desc describe com.example.MyService\n</code></pre></p>"},{"location":"faq/#why-is-my-queue-constantly-full","title":"Why is my queue constantly full?","text":"<p>Cause: Kafka producer throughput &lt; gRPC message rate.</p> <p>Solutions:</p> <ol> <li> <p>Increase queue size (temporary):    <pre><code>grpc.message.queue.size=50000\n</code></pre></p> </li> <li> <p>Optimize Kafka producer (permanent):    <pre><code>producer.linger.ms=10\nproducer.batch.size=32768\nproducer.compression.type=lz4\n</code></pre></p> </li> <li> <p>Scale Kafka infrastructure:</p> </li> <li>Add more brokers</li> <li>Increase partition count</li> <li>Use SSD storage</li> </ol>"},{"location":"faq/#why-do-i-see-sequence-gaps-in-logs","title":"Why do I see sequence gaps in logs?","text":"<p>Cause: Messages lost due to queue overflow or network issues.</p> <p>Investigation: <pre><code># Check for gap warnings\ngrep \"event=sequence_gap\" $KAFKA_HOME/logs/connect.log\n\n# Check queue utilization\n# Monitor QueueUtilizationPercent metric via JMX\n</code></pre></p> <p>Solutions: - Increase <code>grpc.message.queue.size</code> - Optimize Kafka producer settings - Investigate network stability</p>"},{"location":"faq/#compatibility","title":"Compatibility","text":""},{"location":"faq/#does-this-work-with-kafka-2x","title":"Does this work with Kafka 2.x?","text":"<p>No, minimum Kafka version is 3.9.0. The connector uses APIs introduced in Kafka 3.x.</p>"},{"location":"faq/#does-this-work-with-java-8","title":"Does this work with Java 8?","text":"<p>No, minimum Java version is 11. The connector uses Java 11 language features and gRPC Java 1.60.0 requires Java 11+.</p>"},{"location":"faq/#does-this-work-with-kubernetes","title":"Does this work with Kubernetes?","text":"<p>Yes, deploy Kafka Connect in Kubernetes and include this connector:</p> <ul> <li>Strimzi Kafka Operator - Build custom Connect image</li> <li>Confluent for Kubernetes - Use custom Connect image</li> <li>Helm Charts - Mount plugin directory via ConfigMap/PersistentVolume</li> </ul>"},{"location":"faq/#does-this-work-with-docker","title":"Does this work with Docker?","text":"<p>Yes. Create a custom image:</p> <pre><code>FROM confluentinc/cp-kafka-connect:7.5.0\n\n# Copy the uber JAR (includes all dependencies)\nCOPY kafka-connect-grpc-1.0.0-jar-with-dependencies.jar \\\n  /usr/share/confluent-hub-components/kafka-connect-grpc/\n</code></pre>"},{"location":"faq/#still-have-questions","title":"Still Have Questions?","text":"<ul> <li>GitHub Issues: Open an issue</li> <li>Slack Community: Join Conduktor Slack</li> <li>Documentation: Browse documentation</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you install, configure, and deploy your first Kafka Connect gRPC connector.</p>"},{"location":"getting-started/#overview","title":"Overview","text":"<p>The Kafka Connect gRPC Source Connector enables you to stream real-time data from any gRPC server streaming endpoint directly into Apache Kafka topics. It handles connection management, reconnection logic, TLS/mTLS, and integrates seamlessly with Kafka Connect's distributed architecture.</p>"},{"location":"getting-started/#what-youll-learn","title":"What You'll Learn","text":"<p>In this section, you'll learn how to:</p> <ol> <li>Prerequisites - Verify your environment has the required dependencies</li> <li>Installation - Install the connector in your Kafka Connect cluster (see main README)</li> <li>Configuration - Configure all connector parameters</li> <li>Quick Start - Deploy your first connector and verify it's working (see main README)</li> </ol>"},{"location":"getting-started/#deployment-options","title":"Deployment Options","text":"<p>Choose the deployment method that best fits your environment:</p>"},{"location":"getting-started/#distributed-mode-production","title":"Distributed Mode (Production)","text":"<p>Best for: - Production deployments - High availability requirements - Multiple connectors - Horizontal scaling</p> <p>Configuration: <pre><code># config/connect-distributed.properties\nplugin.path=/usr/local/share/kafka/plugins\n</code></pre></p>"},{"location":"getting-started/#standalone-mode-development","title":"Standalone Mode (Development)","text":"<p>Best for: - Local development - Testing - Single connector instances - Quick prototyping</p> <p>Configuration: <pre><code># config/connect-standalone.properties\nplugin.path=/usr/local/share/kafka/plugins\n</code></pre></p>"},{"location":"getting-started/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>Java: 11 or higher</li> <li>Kafka: 3.9.0 or higher</li> <li>Memory: 512 MB RAM for connector</li> <li>Network: Access to gRPC server endpoint</li> <li>Proto Descriptor: .desc file for your gRPC service (optional but recommended)</li> </ul>"},{"location":"getting-started/#recommended-for-production","title":"Recommended for Production","text":"<ul> <li>Java: 17 (LTS)</li> <li>Kafka: Latest stable version</li> <li>Memory: 2 GB RAM for Kafka Connect worker</li> <li>CPU: 2+ cores</li> <li>Network: Low-latency connection to gRPC server</li> </ul>"},{"location":"getting-started/#support-matrix","title":"Support Matrix","text":"Component Minimum Version Recommended Version Tested Versions Java 11 17 11, 17, 21 Kafka 3.9.0 3.9.0+ 3.9.0 Maven 3.6+ 3.9+ 3.6, 3.8, 3.9 gRPC Java 1.60.0 1.60.0 1.60.0 Protobuf 3.25.0 3.25.0 3.25.0"},{"location":"getting-started/#quick-links","title":"Quick Links","text":""},{"location":"getting-started/#main-readme","title":"Main README","text":"<p>Complete documentation with installation, configuration, and usage examples.</p>"},{"location":"getting-started/#configuration-reference","title":"Configuration Reference","text":"<p>Detailed reference for all connector configuration parameters.</p>"},{"location":"getting-started/#faq","title":"FAQ","text":"<p>Frequently asked questions and troubleshooting tips.</p>"},{"location":"getting-started/#changelog","title":"Changelog","text":"<p>Version history, new features, and bug fixes.</p>"},{"location":"getting-started/#before-you-begin","title":"Before You Begin","text":"<p>Check Your Environment</p> <p>Before proceeding, ensure you have:</p> <ul> <li> Java 11+ installed (<code>java -version</code>)</li> <li> Kafka 3.9.0+ running</li> <li> Access to build the connector (Maven 3.6+)</li> <li> Network access to your gRPC server</li> <li> Protocol Buffer descriptor file (.desc) for your service</li> </ul> <p>gRPC Server Requirements</p> <p>Your gRPC server must implement a server streaming method. This connector does not support:</p> <ul> <li>Unary RPCs (request-response)</li> <li>Client streaming</li> <li>Bidirectional streaming</li> </ul> <p>Only server streaming methods are compatible with this connector.</p>"},{"location":"getting-started/#generating-proto-descriptors","title":"Generating Proto Descriptors","text":"<p>To use dynamic message handling, generate a Protocol Buffer descriptor file:</p> <pre><code># Generate .desc file with all dependencies\nprotoc --descriptor_set_out=service.desc \\\n  --include_imports \\\n  your_service.proto\n\n# Verify the descriptor was created\nfile service.desc\n# Output: service.desc: data\n</code></pre> <p>The descriptor file contains all the schema information needed for the connector to serialize and deserialize messages without code generation.</p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Ready to install? Start with:</p> <ol> <li>Prerequisites - Verify your environment</li> <li>Main README - Follow the installation guide</li> <li>Configuration - Learn about all configuration options</li> <li>Examples - Deploy your first connector</li> </ol> <p>Need help? Check our FAQ or open an issue.</p>"},{"location":"getting-started/configuration/","title":"Configuration Reference","text":"<p>Complete reference for all Kafka Connect gRPC Source Connector configuration parameters.</p>"},{"location":"getting-started/configuration/#required-configuration","title":"Required Configuration","text":"<p>These parameters must be specified for the connector to start:</p>"},{"location":"getting-started/configuration/#grpc-server-connection","title":"gRPC Server Connection","text":"Parameter Type Description Example <code>grpc.server.host</code> String gRPC server hostname or IP address <code>localhost</code>, <code>grpc.example.com</code> <code>grpc.server.port</code> Integer gRPC server port <code>9090</code>, <code>443</code> <code>grpc.service.name</code> String Fully qualified service name from proto <code>com.example.EventService</code> <code>grpc.method.name</code> String Server streaming method name <code>StreamEvents</code>"},{"location":"getting-started/configuration/#kafka-configuration","title":"Kafka Configuration","text":"Parameter Type Description Example <code>kafka.topic</code> String Target Kafka topic for gRPC messages <code>grpc-events</code>, <code>streaming-data</code>"},{"location":"getting-started/configuration/#optional-configuration","title":"Optional Configuration","text":""},{"location":"getting-started/configuration/#request-configuration","title":"Request Configuration","text":"Parameter Type Default Description <code>grpc.request.message</code> String <code>{}</code> JSON representation of the request message sent to the gRPC method <code>grpc.proto.descriptor</code> String <code>null</code> Path to .desc descriptor file or base64-encoded descriptor <p>Example: <pre><code>{\n  \"grpc.request.message\": \"{\\\"filter\\\":\\\"active\\\",\\\"limit\\\":100}\",\n  \"grpc.proto.descriptor\": \"/path/to/service.desc\"\n}\n</code></pre></p>"},{"location":"getting-started/configuration/#tlsmtls-configuration","title":"TLS/mTLS Configuration","text":"Parameter Type Default Description <code>grpc.tls.enabled</code> Boolean <code>false</code> Enable TLS for gRPC connection <code>grpc.tls.ca.cert</code> String <code>null</code> Path to CA certificate file for server verification <code>grpc.tls.client.cert</code> String <code>null</code> Path to client certificate for mutual TLS <code>grpc.tls.client.key</code> String <code>null</code> Path to client private key for mutual TLS <p>Example (TLS only): <pre><code>{\n  \"grpc.tls.enabled\": \"true\",\n  \"grpc.tls.ca.cert\": \"/etc/ssl/certs/ca.crt\"\n}\n</code></pre></p> <p>Example (mTLS): <pre><code>{\n  \"grpc.tls.enabled\": \"true\",\n  \"grpc.tls.ca.cert\": \"/etc/ssl/certs/ca.crt\",\n  \"grpc.tls.client.cert\": \"/etc/ssl/certs/client.crt\",\n  \"grpc.tls.client.key\": \"/etc/ssl/private/client.key\"\n}\n</code></pre></p>"},{"location":"getting-started/configuration/#metadataheaders-configuration","title":"Metadata/Headers Configuration","text":"Parameter Type Default Description <code>grpc.metadata</code> String <code>null</code> Custom metadata in format: <code>key1:value1,key2:value2</code> <code>grpc.metadata.&lt;key&gt;</code> String <code>null</code> Individual metadata entry (alternative to comma-separated format) <p>Example (comma-separated): <pre><code>{\n  \"grpc.metadata\": \"authorization:Bearer token123,x-api-key:key456\"\n}\n</code></pre></p> <p>Example (individual entries): <pre><code>{\n  \"grpc.metadata.authorization\": \"Bearer token123\",\n  \"grpc.metadata.x-api-key\": \"key456\",\n  \"grpc.metadata.x-request-id\": \"req-789\"\n}\n</code></pre></p>"},{"location":"getting-started/configuration/#reconnection-configuration","title":"Reconnection Configuration","text":"Parameter Type Default Description <code>grpc.reconnect.enabled</code> Boolean <code>true</code> Enable automatic reconnection on disconnect <code>grpc.reconnect.interval.ms</code> Long <code>5000</code> Initial reconnection interval in milliseconds <code>grpc.reconnect.max.attempts</code> Integer <code>-1</code> Maximum reconnection attempts (-1 for infinite) <code>grpc.reconnect.backoff.max.ms</code> Long <code>60000</code> Maximum backoff delay for exponential backoff <p>Backoff Calculation: <pre><code>delay = min(interval * 2^attempt, backoff.max)\n</code></pre></p> <p>Example (aggressive reconnection): <pre><code>{\n  \"grpc.reconnect.enabled\": \"true\",\n  \"grpc.reconnect.interval.ms\": \"1000\",\n  \"grpc.reconnect.max.attempts\": \"-1\",\n  \"grpc.reconnect.backoff.max.ms\": \"30000\"\n}\n</code></pre></p> <p>Example (limited retries): <pre><code>{\n  \"grpc.reconnect.enabled\": \"true\",\n  \"grpc.reconnect.interval.ms\": \"5000\",\n  \"grpc.reconnect.max.attempts\": \"10\",\n  \"grpc.reconnect.backoff.max.ms\": \"120000\"\n}\n</code></pre></p>"},{"location":"getting-started/configuration/#advanced-configuration","title":"Advanced Configuration","text":"Parameter Type Default Description <code>grpc.message.queue.size</code> Integer <code>10000</code> Maximum size of the message buffer queue <code>grpc.connection.timeout.ms</code> Long <code>30000</code> Connection timeout in milliseconds <code>grpc.keepalive.time.ms</code> Long <code>30000</code> Keepalive time (0 to disable) <code>grpc.keepalive.timeout.ms</code> Long <code>10000</code> Keepalive timeout <code>grpc.max.inbound.message.size</code> Integer <code>4194304</code> Maximum inbound message size in bytes (4MB default) <p>Queue Size Recommendations:</p> Use Case Queue Size Low-volume (&lt; 100 msg/sec) 1000-5000 Medium-volume (100-1000 msg/sec) 10000-20000 High-volume (&gt; 1000 msg/sec) 50000-100000 <p>Keepalive Recommendations:</p> Network Condition Keepalive Time Keepalive Timeout Stable local network 60000 (60s) 10000 (10s) Cloud-to-cloud (same region) 30000 (30s) 10000 (10s) Cross-region 20000 (20s) 5000 (5s) Unstable network 10000 (10s) 3000 (3s)"},{"location":"getting-started/configuration/#complete-configuration-examples","title":"Complete Configuration Examples","text":""},{"location":"getting-started/configuration/#basic-configuration","title":"Basic Configuration","text":"<p>Minimal configuration for plaintext gRPC:</p> <pre><code>{\n  \"name\": \"grpc-basic-connector\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.grpc.GrpcSourceConnector\",\n    \"tasks.max\": \"1\",\n    \"grpc.server.host\": \"localhost\",\n    \"grpc.server.port\": \"9090\",\n    \"grpc.service.name\": \"com.example.EventService\",\n    \"grpc.method.name\": \"StreamEvents\",\n    \"kafka.topic\": \"grpc-events\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#production-configuration-with-tls","title":"Production Configuration with TLS","text":"<p>Recommended configuration for production with TLS:</p> <pre><code>{\n  \"name\": \"grpc-prod-connector\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.grpc.GrpcSourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"grpc.server.host\": \"grpc.production.example.com\",\n    \"grpc.server.port\": \"443\",\n    \"grpc.service.name\": \"com.example.production.EventService\",\n    \"grpc.method.name\": \"StreamEvents\",\n\n    \"grpc.tls.enabled\": \"true\",\n    \"grpc.tls.ca.cert\": \"/etc/ssl/certs/production-ca.crt\",\n\n    \"grpc.request.message\": \"{\\\"environment\\\":\\\"production\\\",\\\"version\\\":\\\"v1\\\"}\",\n    \"grpc.proto.descriptor\": \"/etc/kafka/descriptors/service.desc\",\n\n    \"grpc.metadata.authorization\": \"Bearer ${file:/etc/kafka/secrets.properties:api.token}\",\n    \"grpc.metadata.x-environment\": \"production\",\n\n    \"grpc.reconnect.enabled\": \"true\",\n    \"grpc.reconnect.interval.ms\": \"5000\",\n    \"grpc.reconnect.max.attempts\": \"-1\",\n    \"grpc.reconnect.backoff.max.ms\": \"60000\",\n\n    \"grpc.message.queue.size\": \"50000\",\n    \"grpc.connection.timeout.ms\": \"30000\",\n    \"grpc.keepalive.time.ms\": \"30000\",\n    \"grpc.keepalive.timeout.ms\": \"10000\",\n    \"grpc.max.inbound.message.size\": \"8388608\",\n\n    \"kafka.topic\": \"production-grpc-events\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#high-security-mtls-configuration","title":"High-Security mTLS Configuration","text":"<p>Maximum security with mutual TLS:</p> <pre><code>{\n  \"name\": \"grpc-mtls-connector\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.grpc.GrpcSourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"grpc.server.host\": \"secure-grpc.example.com\",\n    \"grpc.server.port\": \"443\",\n    \"grpc.service.name\": \"com.example.secure.DataService\",\n    \"grpc.method.name\": \"StreamSecureData\",\n\n    \"grpc.tls.enabled\": \"true\",\n    \"grpc.tls.ca.cert\": \"/etc/ssl/certs/ca.crt\",\n    \"grpc.tls.client.cert\": \"/etc/ssl/certs/client.crt\",\n    \"grpc.tls.client.key\": \"${file:/etc/kafka/secrets.properties:client.key.path}\",\n\n    \"grpc.metadata.authorization\": \"${file:/etc/kafka/secrets.properties:grpc.auth.token}\",\n    \"grpc.metadata.x-client-id\": \"kafka-connect-prod-01\",\n\n    \"grpc.proto.descriptor\": \"/etc/kafka/descriptors/secure-service.desc\",\n\n    \"kafka.topic\": \"secure-data-stream\",\n\n    \"config.providers\": \"file\",\n    \"config.providers.file.class\": \"org.apache.kafka.common.config.provider.FileConfigProvider\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#high-throughput-configuration","title":"High-Throughput Configuration","text":"<p>Optimized for high message volume:</p> <pre><code>{\n  \"name\": \"grpc-highthroughput-connector\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.grpc.GrpcSourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"grpc.server.host\": \"streaming.example.com\",\n    \"grpc.server.port\": \"9090\",\n    \"grpc.service.name\": \"com.example.HighVolumeService\",\n    \"grpc.method.name\": \"StreamHighVolume\",\n\n    \"grpc.message.queue.size\": \"100000\",\n    \"grpc.max.inbound.message.size\": \"16777216\",\n\n    \"grpc.keepalive.time.ms\": \"15000\",\n    \"grpc.keepalive.timeout.ms\": \"5000\",\n\n    \"grpc.reconnect.enabled\": \"true\",\n    \"grpc.reconnect.interval.ms\": \"1000\",\n    \"grpc.reconnect.backoff.max.ms\": \"10000\",\n\n    \"kafka.topic\": \"high-volume-stream\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#developmenttesting-configuration","title":"Development/Testing Configuration","text":"<p>Minimal setup for local development:</p> <pre><code>{\n  \"name\": \"grpc-dev-connector\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.grpc.GrpcSourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"grpc.server.host\": \"localhost\",\n    \"grpc.server.port\": \"9090\",\n    \"grpc.service.name\": \"com.example.TestService\",\n    \"grpc.method.name\": \"StreamTest\",\n\n    \"grpc.message.queue.size\": \"1000\",\n    \"grpc.reconnect.interval.ms\": \"1000\",\n    \"grpc.reconnect.max.attempts\": \"5\",\n\n    \"kafka.topic\": \"test-grpc-stream\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#configuration-validation","title":"Configuration Validation","text":"<p>The connector validates configuration on startup:</p>"},{"location":"getting-started/configuration/#common-validation-errors","title":"Common Validation Errors","text":"Error Cause Solution \"Missing required configuration\" Required parameter not set Add the missing parameter \"Invalid port number\" Port outside 1-65535 Use valid port range \"Cannot read TLS certificate\" Certificate file not accessible Check file path and permissions \"Invalid proto descriptor\" Descriptor file corrupted or invalid Regenerate with <code>protoc --descriptor_set_out</code> \"Service not found in descriptor\" Service name doesn't match Verify service name with <code>grpcurl -protoset</code>"},{"location":"getting-started/configuration/#validation-checklist","title":"Validation Checklist","text":"<p>Before deploying:</p> <ul> <li> All required parameters are set</li> <li> gRPC server is accessible on specified host:port</li> <li> Service and method names match proto definition</li> <li> TLS certificates are valid and accessible</li> <li> Proto descriptor contains the service definition</li> <li> Kafka topic exists or auto-creation is enabled</li> <li> Request message JSON is valid (if specified)</li> </ul>"},{"location":"getting-started/configuration/#dynamic-configuration-updates","title":"Dynamic Configuration Updates","text":"<p>Some parameters can be updated without restarting:</p>"},{"location":"getting-started/configuration/#updatable-parameters","title":"Updatable Parameters","text":"<ul> <li><code>grpc.message.queue.size</code> (takes effect on reconnection)</li> <li><code>grpc.reconnect.interval.ms</code></li> <li><code>grpc.reconnect.max.attempts</code></li> <li><code>kafka.topic</code> (new messages only)</li> </ul>"},{"location":"getting-started/configuration/#non-updatable-parameters-require-restart","title":"Non-Updatable Parameters (require restart)","text":"<ul> <li><code>grpc.server.host</code></li> <li><code>grpc.server.port</code></li> <li><code>grpc.service.name</code></li> <li><code>grpc.method.name</code></li> <li><code>grpc.tls.*</code> (all TLS settings)</li> <li><code>grpc.proto.descriptor</code></li> </ul> <p>Update configuration: <pre><code>curl -X PUT http://localhost:8083/connectors/grpc-connector/config \\\n  -H \"Content-Type: application/json\" \\\n  -d @updated-config.json\n</code></pre></p>"},{"location":"getting-started/configuration/#best-practices","title":"Best Practices","text":""},{"location":"getting-started/configuration/#security","title":"Security","text":"<ol> <li> <p>Always use TLS in production <pre><code>\"grpc.tls.enabled\": \"true\"\n</code></pre></p> </li> <li> <p>Store secrets securely <pre><code>\"config.providers\": \"file\",\n\"grpc.tls.client.key\": \"${file:/etc/kafka/secrets.properties:key.path}\"\n</code></pre></p> </li> <li> <p>Use mTLS for sensitive data <pre><code>\"grpc.tls.client.cert\": \"/path/to/client.crt\",\n\"grpc.tls.client.key\": \"/path/to/client.key\"\n</code></pre></p> </li> </ol>"},{"location":"getting-started/configuration/#performance","title":"Performance","text":"<ol> <li>Size queue appropriately</li> <li>Monitor <code>QueueUtilizationPercent</code> metric</li> <li> <p>Increase if consistently &gt; 80%</p> </li> <li> <p>Tune keepalive for network conditions</p> </li> <li>Shorter intervals for unstable networks</li> <li> <p>Longer intervals for stable connections</p> </li> <li> <p>Adjust message size limits</p> </li> <li>Set <code>grpc.max.inbound.message.size</code> based on actual message size</li> <li>Don't set unnecessarily high (wastes memory)</li> </ol>"},{"location":"getting-started/configuration/#reliability","title":"Reliability","text":"<ol> <li> <p>Enable reconnection <pre><code>\"grpc.reconnect.enabled\": \"true\",\n\"grpc.reconnect.max.attempts\": \"-1\"\n</code></pre></p> </li> <li> <p>Use exponential backoff <pre><code>\"grpc.reconnect.interval.ms\": \"5000\",\n\"grpc.reconnect.backoff.max.ms\": \"60000\"\n</code></pre></p> </li> <li> <p>Monitor offset tracking</p> </li> <li>Check logs for sequence gap warnings</li> <li>Investigate repeated gaps</li> </ol>"},{"location":"getting-started/configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"getting-started/configuration/#development","title":"Development","text":"<ul> <li>Small queue size (1000)</li> <li>Short reconnection interval (1000ms)</li> <li>Limited retry attempts (5-10)</li> <li>Plaintext connection acceptable</li> </ul>"},{"location":"getting-started/configuration/#staging","title":"Staging","text":"<ul> <li>Medium queue size (10000)</li> <li>Normal reconnection interval (5000ms)</li> <li>TLS enabled</li> <li>Production-like settings</li> </ul>"},{"location":"getting-started/configuration/#production","title":"Production","text":"<ul> <li>Large queue size (50000+)</li> <li>Exponential backoff (5000-60000ms)</li> <li>Infinite retries (-1)</li> <li>TLS/mTLS required</li> <li>Keepalive tuned for network</li> <li>Secrets externalized</li> </ul> <p>Need help? Check our FAQ or open an issue.</p>"},{"location":"getting-started/prerequisites/","title":"Prerequisites","text":"<p>Before installing the Kafka Connect gRPC connector, ensure your environment meets the following requirements.</p>"},{"location":"getting-started/prerequisites/#required-software","title":"Required Software","text":""},{"location":"getting-started/prerequisites/#java-development-kit-jdk","title":"Java Development Kit (JDK)","text":"<p>Minimum Version: Java 11 Recommended: Java 17 (LTS)</p> Check Java VersionInstall Java (Ubuntu/Debian)Install Java (macOS)Install Java (RHEL/CentOS) <pre><code>java -version\n</code></pre> <p>Expected output: <pre><code>openjdk version \"17.0.9\" 2023-10-17 LTS\nOpenJDK Runtime Environment (build 17.0.9+9-LTS)\n</code></pre></p> <pre><code>sudo apt update\nsudo apt install openjdk-17-jdk\n</code></pre> <pre><code>brew install openjdk@17\n</code></pre> <pre><code>sudo yum install java-17-openjdk-devel\n</code></pre>"},{"location":"getting-started/prerequisites/#apache-kafka","title":"Apache Kafka","text":"<p>Minimum Version: 3.9.0 Download: Apache Kafka Downloads</p> Verify Kafka InstallationQuick Kafka Setup (Local) <pre><code>kafka-topics.sh --version\n</code></pre> <p>Expected output: <pre><code>3.9.0 (Commit:...)\n</code></pre></p> <pre><code># Download Kafka\nwget https://downloads.apache.org/kafka/3.9.0/kafka_2.13-3.9.0.tgz\ntar -xzf kafka_2.13-3.9.0.tgz\ncd kafka_2.13-3.9.0\n\n# Start Kafka (KRaft mode)\nKAFKA_CLUSTER_ID=\"$(bin/kafka-storage.sh random-uuid)\"\nbin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties\nbin/kafka-server-start.sh config/kraft/server.properties\n</code></pre>"},{"location":"getting-started/prerequisites/#maven-for-building-from-source","title":"Maven (for building from source)","text":"<p>Minimum Version: 3.6+ Recommended: 3.9+</p> <pre><code>mvn --version\n</code></pre> <p>Expected output: <pre><code>Apache Maven 3.9.5\nMaven home: /usr/share/maven\nJava version: 17.0.9\n</code></pre></p>"},{"location":"getting-started/prerequisites/#protocol-buffers-compiler-protoc","title":"Protocol Buffers Compiler (protoc)","text":"<p>Required for: Generating .desc descriptor files Minimum Version: 3.0+ Recommended: 3.25.0+</p> Check protoc VersionInstall protoc (Ubuntu/Debian)Install protoc (macOS)Install protoc (Manual) <pre><code>protoc --version\n</code></pre> <p>Expected output: <pre><code>libprotoc 3.25.0\n</code></pre></p> <pre><code>sudo apt update\nsudo apt install protobuf-compiler\n</code></pre> <pre><code>brew install protobuf\n</code></pre> <pre><code># Download from GitHub releases\nPROTOC_VERSION=25.0\nwget https://github.com/protocolbuffers/protobuf/releases/download/v${PROTOC_VERSION}/protoc-${PROTOC_VERSION}-linux-x86_64.zip\nunzip protoc-${PROTOC_VERSION}-linux-x86_64.zip -d /usr/local\n</code></pre>"},{"location":"getting-started/prerequisites/#network-requirements","title":"Network Requirements","text":""},{"location":"getting-started/prerequisites/#grpc-server-connectivity","title":"gRPC Server Connectivity","text":"<p>The connector requires network access to gRPC servers:</p> Protocol Default Port Purpose gRPC (plaintext) 9090 Unencrypted gRPC connections gRPC (TLS) 443 or custom TLS-encrypted gRPC connections <p>Test gRPC Connectivity</p> <pre><code># Install grpcurl (gRPC testing tool)\ngo install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest\n\n# Test connection and list services\ngrpcurl -plaintext localhost:9090 list\n\n# Test server streaming method\ngrpcurl -plaintext localhost:9090 \\\n  com.example.MyService/StreamData\n</code></pre>"},{"location":"getting-started/prerequisites/#firewall-configuration","title":"Firewall Configuration","text":"<p>If behind a corporate firewall, ensure HTTP/2 traffic is allowed:</p> <pre><code># Test with curl (HTTP/2)\ncurl -v --http2 https://grpc-server:443\n\n# Expected: Connection successful, HTTP/2 protocol negotiated\n</code></pre>"},{"location":"getting-started/prerequisites/#proxy-configuration","title":"Proxy Configuration","text":"<p>If using a corporate proxy:</p> <pre><code># Set proxy environment variables\nexport https_proxy=http://proxy.company.com:8080\nexport http_proxy=http://proxy.company.com:8080\n\n# Configure Java proxy (add to Kafka Connect startup)\nexport KAFKA_OPTS=\"-Dhttps.proxyHost=proxy.company.com \\\n                   -Dhttps.proxyPort=8080 \\\n                   -Dhttp.proxyHost=proxy.company.com \\\n                   -Dhttp.proxyPort=8080\"\n</code></pre>"},{"location":"getting-started/prerequisites/#grpc-server-requirements","title":"gRPC Server Requirements","text":""},{"location":"getting-started/prerequisites/#server-streaming-method","title":"Server Streaming Method","text":"<p>The connector requires a server streaming gRPC method:</p> <pre><code>service EventService {\n  // \u2705 Supported: Server streaming\n  rpc StreamEvents(EventRequest) returns (stream Event);\n\n  // \u274c Not supported: Unary\n  rpc GetEvent(EventRequest) returns (Event);\n\n  // \u274c Not supported: Client streaming\n  rpc UploadEvents(stream Event) returns (UploadResponse);\n\n  // \u274c Not supported: Bidirectional streaming\n  rpc SyncEvents(stream Event) returns (stream Event);\n}\n</code></pre>"},{"location":"getting-started/prerequisites/#protocol-buffer-descriptor","title":"Protocol Buffer Descriptor","text":"<p>Generate a descriptor file for your service:</p> <pre><code># Generate .desc file with all dependencies\nprotoc --descriptor_set_out=service.desc \\\n  --include_imports \\\n  your_service.proto\n\n# Verify descriptor contains your service\ngrpcurl -protoset service.desc list\n</code></pre> <p>Include Imports</p> <p>Always use <code>--include_imports</code> when generating descriptors. Without it, the connector cannot resolve message types from imported proto files.</p>"},{"location":"getting-started/prerequisites/#kafka-connect-setup","title":"Kafka Connect Setup","text":""},{"location":"getting-started/prerequisites/#distributed-mode-recommended-for-production","title":"Distributed Mode (Recommended for Production)","text":"<p>Ensure Kafka Connect is running in distributed mode:</p> <pre><code># Check if Connect is running\ncurl http://localhost:8083/\n</code></pre> <p>Expected response: <pre><code>{\n  \"version\": \"3.9.0\",\n  \"commit\": \"...\",\n  \"kafka_cluster_id\": \"...\"\n}\n</code></pre></p>"},{"location":"getting-started/prerequisites/#internal-topics-configuration","title":"Internal Topics Configuration","text":"<p>Kafka Connect in distributed mode requires three internal topics. These are typically auto-created, but for production you should pre-create them with proper replication:</p> <pre><code># In connect-distributed.properties\noffset.storage.topic=connect-offsets\noffset.storage.replication.factor=3\noffset.storage.partitions=25\n\nconfig.storage.topic=connect-configs\nconfig.storage.replication.factor=3\nconfig.storage.partitions=1\n\nstatus.storage.topic=connect-status\nstatus.storage.replication.factor=3\nstatus.storage.partitions=5\n</code></pre> <p>Topic Purpose</p> <ul> <li>connect-offsets: Stores source connector offsets (sequence numbers for gRPC)</li> <li>connect-configs: Stores connector and task configurations</li> <li>connect-status: Stores connector and task status</li> </ul>"},{"location":"getting-started/prerequisites/#producer-configuration","title":"Producer Configuration","text":"<p>Configure producer settings for source connectors in <code>connect-distributed.properties</code>:</p> <pre><code># Optimize for throughput\nproducer.linger.ms=10\nproducer.batch.size=32768\nproducer.compression.type=lz4\nproducer.acks=1\n</code></pre>"},{"location":"getting-started/prerequisites/#plugin-directory","title":"Plugin Directory","text":"<p>Verify the plugin path is configured:</p> <pre><code># Check connect-distributed.properties\ngrep plugin.path $KAFKA_HOME/config/connect-distributed.properties\n</code></pre> <p>Expected output: <pre><code>plugin.path=/usr/local/share/kafka/plugins\n</code></pre></p> <p>Plugin Path Must Exist</p> <p>The plugin directory must exist and have proper permissions: <pre><code>sudo mkdir -p /usr/local/share/kafka/plugins\nsudo chown -R $USER:$USER /usr/local/share/kafka/plugins\n</code></pre></p>"},{"location":"getting-started/prerequisites/#resource-requirements","title":"Resource Requirements","text":""},{"location":"getting-started/prerequisites/#minimum-resources","title":"Minimum Resources","text":"<p>For development/testing:</p> Resource Requirement CPU 1 core Memory 512 MB for connector Disk 100 MB for JAR files Network 10 Mbps"},{"location":"getting-started/prerequisites/#production-resources","title":"Production Resources","text":"<p>For production deployments:</p> Resource Requirement CPU 2+ cores Memory 2 GB for Kafka Connect worker Disk 1 GB (for JARs + logs) Network 100+ Mbps, low latency to gRPC server"},{"location":"getting-started/prerequisites/#memory-configuration","title":"Memory Configuration","text":"<p>Configure heap size for Kafka Connect:</p> <pre><code># In connect-distributed.sh or systemd service\nexport KAFKA_HEAP_OPTS=\"-Xms2G -Xmx2G\"\n</code></pre>"},{"location":"getting-started/prerequisites/#security-configuration","title":"Security Configuration","text":""},{"location":"getting-started/prerequisites/#tlsmtls-certificates","title":"TLS/mTLS Certificates","text":"<p>For secure gRPC connections, prepare certificate files:</p> <pre><code># CA certificate (for server verification)\n/path/to/ca.crt\n\n# Client certificate (for mTLS)\n/path/to/client.crt\n\n# Client private key (for mTLS)\n/path/to/client.key\n</code></pre> <p>Verify certificates:</p> <pre><code># Check certificate validity\nopenssl x509 -in ca.crt -text -noout\n\n# Test mTLS connection\ngrpcurl -cacert ca.crt \\\n  -cert client.crt \\\n  -key client.key \\\n  grpc-server:443 list\n</code></pre>"},{"location":"getting-started/prerequisites/#secure-jmx-access","title":"Secure JMX Access","text":"<p>For production, enable JMX authentication:</p> <pre><code># Create password file\necho \"admin changeit\" &gt; /etc/kafka/jmx.password\nchmod 600 /etc/kafka/jmx.password\n\n# Create access file\necho \"admin readwrite\" &gt; /etc/kafka/jmx.access\nchmod 644 /etc/kafka/jmx.access\n\n# Configure Kafka Connect\nexport KAFKA_JMX_OPTS=\"-Dcom.sun.management.jmxremote \\\n  -Dcom.sun.management.jmxremote.authenticate=true \\\n  -Dcom.sun.management.jmxremote.password.file=/etc/kafka/jmx.password \\\n  -Dcom.sun.management.jmxremote.access.file=/etc/kafka/jmx.access \\\n  -Dcom.sun.management.jmxremote.ssl=true\"\n</code></pre> <p>Never Run JMX Without Authentication in Production</p> <p>Default JMX configuration with <code>authenticate=false</code> exposes your connector to unauthorized access.</p>"},{"location":"getting-started/prerequisites/#protect-secrets-in-configuration","title":"Protect Secrets in Configuration","text":"<p>Do NOT store sensitive data in plaintext config files. Use Kafka Connect's ConfigProvider:</p> <pre><code>{\n  \"grpc.tls.client.key\": \"${file:/etc/kafka/secrets.properties:grpc.client.key}\",\n  \"config.providers\": \"file\",\n  \"config.providers.file.class\": \"org.apache.kafka.common.config.provider.FileConfigProvider\"\n}\n</code></pre> <p>Create <code>/etc/kafka/secrets.properties</code> with restricted permissions:</p> <pre><code>echo \"grpc.client.key=/secure/path/to/client.key\" &gt; /etc/kafka/secrets.properties\nchmod 600 /etc/kafka/secrets.properties\n</code></pre>"},{"location":"getting-started/prerequisites/#optional-tools","title":"Optional Tools","text":""},{"location":"getting-started/prerequisites/#monitoring-tools","title":"Monitoring Tools","text":"<p>For production deployments, consider installing:</p> <ul> <li>JMX Monitoring: JConsole, VisualVM, or JMX Exporter</li> <li>Prometheus: For metrics collection</li> <li>Grafana: For dashboards</li> <li>Loki/ELK: For log aggregation</li> </ul>"},{"location":"getting-started/prerequisites/#development-tools","title":"Development Tools","text":"<p>For connector development:</p> <ul> <li>Git: Version control</li> <li>Docker: Containerized Kafka and gRPC server setup</li> <li>grpcurl: gRPC command-line client for testing</li> <li>curl/jq: API testing and JSON parsing</li> <li>BloomRPC: GUI client for testing gRPC services</li> </ul>"},{"location":"getting-started/prerequisites/#verification-checklist","title":"Verification Checklist","text":"<p>Before proceeding to installation, verify:</p> <ul> <li> Java 11+ is installed and <code>java -version</code> works</li> <li> Kafka 3.9.0+ is running</li> <li> Kafka Connect REST API is accessible at <code>http://localhost:8083/</code></li> <li> Plugin directory exists and is writable</li> <li> Maven 3.6+ is installed (for building from source)</li> <li> protoc is installed for generating descriptors</li> <li> Network access to gRPC server is available</li> <li> gRPC server has a server streaming method</li> <li> Protocol Buffer descriptor file is generated</li> </ul>"},{"location":"getting-started/prerequisites/#troubleshooting-prerequisites","title":"Troubleshooting Prerequisites","text":""},{"location":"getting-started/prerequisites/#java-version-issues","title":"Java Version Issues","text":"<p>Problem: Wrong Java version</p> <pre><code># Check all Java installations\nls -la /usr/lib/jvm/\n\n# Set JAVA_HOME\nexport JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64\nexport PATH=$JAVA_HOME/bin:$PATH\n</code></pre>"},{"location":"getting-started/prerequisites/#kafka-not-running","title":"Kafka Not Running","text":"<p>Problem: Kafka Connect not accessible</p> <pre><code># Check Kafka Connect logs\ntail -f $KAFKA_HOME/logs/connect.log\n\n# Restart Kafka Connect\n$KAFKA_HOME/bin/connect-distributed.sh config/connect-distributed.properties\n</code></pre>"},{"location":"getting-started/prerequisites/#network-connectivity-issues","title":"Network Connectivity Issues","text":"<p>Problem: Cannot reach gRPC server</p> <pre><code># Test DNS resolution\nnslookup grpc-server.example.com\n\n# Test port connectivity\ntelnet grpc-server.example.com 9090\n\n# Test gRPC service\ngrpcurl -plaintext grpc-server.example.com:9090 list\n</code></pre>"},{"location":"getting-started/prerequisites/#proto-descriptor-issues","title":"Proto Descriptor Issues","text":"<p>Problem: Cannot generate descriptor file</p> <pre><code># Ensure protoc is installed\nwhich protoc\n\n# Check proto file syntax\nprotoc --syntax-check your_service.proto\n\n# Generate with verbose output\nprotoc --descriptor_set_out=service.desc \\\n  --include_imports \\\n  --error_format=gcc \\\n  your_service.proto\n</code></pre>"},{"location":"getting-started/prerequisites/#next-steps","title":"Next Steps","text":"<p>Once all prerequisites are met:</p> <ol> <li>Installation - Install the connector</li> <li>Configuration - Configure all connector parameters</li> <li>Quick Start - Deploy your first connector</li> </ol> <p>Need help? Check our FAQ or open an issue.</p>"},{"location":"operations/RUNBOOK/","title":"gRPC Source Connector - Operational Runbook","text":"<p>This runbook provides operational guidance for monitoring, troubleshooting, and maintaining the gRPC Source Connector in production.</p>"},{"location":"operations/RUNBOOK/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Incident Response Decision Tree</li> <li>Monitoring</li> <li>Common Issues</li> <li>Performance Tuning</li> <li>Troubleshooting</li> <li>Recovery Procedures</li> </ul>"},{"location":"operations/RUNBOOK/#incident-response-decision-tree","title":"Incident Response Decision Tree","text":"<p>Use this decision tree when an alert fires or an issue is reported:</p> <pre><code>START: Alert or Issue Reported\n\u2502\n\u251c\u2500 Is connector in RUNNING state?\n\u2502  \u2502  curl http://localhost:8083/connectors/&lt;name&gt;/status | jq '.connector.state'\n\u2502  \u2502\n\u2502  \u2514\u2500 NO \u2192 Go to [Connector Not Running](#issue-connector-not-running)\n\u2502  \u2514\u2500 YES \u2192 Continue \u2193\n\u2502\n\u251c\u2500 Is gRPC connected? (IsConnected = true)\n\u2502  \u2502  Check JMX: io.conduktor.connect.grpc:*/IsConnected\n\u2502  \u2502\n\u2502  \u2514\u2500 NO \u2192 Go to [Connection Issues](#issue-1-connection-keeps-dropping)\n\u2502  \u2514\u2500 YES \u2192 Continue \u2193\n\u2502\n\u251c\u2500 Are messages being received? (MessagesReceived increasing)\n\u2502  \u2502  Check JMX: io.conduktor.connect.grpc:*/MessagesReceived\n\u2502  \u2502\n\u2502  \u2514\u2500 NO \u2192 Go to [No Messages Received](#issue-3-no-messages-received)\n\u2502  \u2514\u2500 YES \u2192 Continue \u2193\n\u2502\n\u251c\u2500 Is queue near capacity? (QueueUtilizationPercent &gt; 80%)\n\u2502  \u2502  Check JMX: io.conduktor.connect.grpc:*/QueueUtilizationPercent\n\u2502  \u2502\n\u2502  \u2514\u2500 YES \u2192 Go to [High Message Drop Rate](#issue-2-high-message-drop-rate)\n\u2502  \u2514\u2500 NO \u2192 Continue \u2193\n\u2502\n\u251c\u2500 Is Kafka write lagging? (RecordsProduced &lt;&lt; MessagesReceived)\n\u2502  \u2502  Check lag: MessagesReceived - RecordsProduced &gt; 10000\n\u2502  \u2502\n\u2502  \u2514\u2500 YES \u2192 Go to [Processing Lag](#issue-4-processing-lag-building-up)\n\u2502  \u2514\u2500 NO \u2192 Continue \u2193\n\u2502\n\u251c\u2500 Are sequence gaps detected?\n\u2502  \u2502  grep \"event=sequence_gap\" $KAFKA_HOME/logs/connect.log\n\u2502  \u2502\n\u2502  \u2514\u2500 YES \u2192 Go to [Sequence Gaps](#issue-5-sequence-gaps-detected)\n\u2502  \u2514\u2500 NO \u2192 Continue \u2193\n\u2502\n\u2514\u2500 Check logs for errors\n   \u2502  grep \"ERROR\\|WARN\" $KAFKA_HOME/logs/connect.log | tail -50\n   \u2502\n   \u2514\u2500 Errors found \u2192 Match error to [Common Issues](#common-issues)\n   \u2514\u2500 No errors \u2192 Monitor, escalate if issue persists\n</code></pre>"},{"location":"operations/RUNBOOK/#quick-commands-reference","title":"Quick Commands Reference","text":"<pre><code># Check connector status\ncurl -s http://localhost:8083/connectors/&lt;name&gt;/status | jq .\n\n# Restart connector\ncurl -X POST http://localhost:8083/connectors/&lt;name&gt;/restart\n\n# Restart specific task\ncurl -X POST http://localhost:8083/connectors/&lt;name&gt;/tasks/0/restart\n\n# Check recent logs\ntail -100 $KAFKA_HOME/logs/connect.log | grep -E \"grpc|ERROR|WARN\"\n\n# Check JMX metrics (requires jmxterm)\necho \"get -b io.conduktor.connect.grpc:* IsConnected\" | \\\n  java -jar jmxterm.jar -l localhost:9999\n</code></pre>"},{"location":"operations/RUNBOOK/#issue-connector-not-running","title":"Issue: Connector Not Running","text":"<p>Symptoms: Connector state is FAILED or task state is FAILED</p> <p>Quick Fix: <pre><code># Check the error message\ncurl -s http://localhost:8083/connectors/&lt;name&gt;/status | jq '.tasks[0].trace'\n\n# Restart connector\ncurl -X POST http://localhost:8083/connectors/&lt;name&gt;/restart\n\n# If still failing, check config and redeploy\ncurl -X DELETE http://localhost:8083/connectors/&lt;name&gt;\ncurl -X POST http://localhost:8083/connectors -H \"Content-Type: application/json\" -d @connector.json\n</code></pre></p> <p>Common Causes: - Invalid gRPC server host/port - TLS certificate issues - Proto descriptor file not found or invalid - Service/method name mismatch - Missing dependencies (ClassNotFoundException)</p>"},{"location":"operations/RUNBOOK/#monitoring","title":"Monitoring","text":""},{"location":"operations/RUNBOOK/#key-jmx-metrics","title":"Key JMX Metrics","text":"<p>The connector exposes JMX metrics under: <pre><code>io.conduktor.connect.grpc:type=GrpcConnector,name=&lt;connector-name&gt;,server=&lt;server&gt;\n</code></pre></p>"},{"location":"operations/RUNBOOK/#counter-metrics","title":"Counter Metrics","text":"<ul> <li>MessagesReceived: Total messages received from gRPC</li> <li>Alert: Rate drops to 0 for &gt; 5 minutes \u2192 Connection or server issue</li> <li> <p>Action: Check <code>IsConnected</code> metric, review logs for gRPC errors</p> </li> <li> <p>MessagesDropped: Messages dropped due to queue overflow</p> </li> <li>Alert: Drop rate &gt; 1% \u2192 Queue capacity insufficient</li> <li> <p>Action: Increase <code>grpc.message.queue.size</code> or optimize Kafka throughput</p> </li> <li> <p>RecordsProduced: Total records written to Kafka</p> </li> <li>Alert: Lag (MessagesReceived - RecordsProduced) &gt; 10000 \u2192 Processing backlog</li> <li>Action: Check Kafka broker health, review producer performance</li> </ul>"},{"location":"operations/RUNBOOK/#queue-metrics","title":"Queue Metrics","text":"<ul> <li>QueueSize: Current number of messages in queue</li> <li>QueueCapacity: Maximum queue capacity</li> <li>QueueUtilizationPercent: (QueueSize / QueueCapacity) * 100</li> <li>Alert: Utilization &gt; 80% \u2192 Approaching capacity</li> <li>Action: Monitor for drops, consider increasing queue size</li> </ul>"},{"location":"operations/RUNBOOK/#connection-metrics","title":"Connection Metrics","text":"<ul> <li>IsConnected: Boolean indicating gRPC connection status</li> <li>Alert: false for &gt; 2 minutes \u2192 Connection failure</li> <li> <p>Action: Check gRPC server availability, verify TLS configuration</p> </li> <li> <p>MillisSinceLastMessage: Time since last message received</p> </li> <li>Alert: &gt; 300000ms (5 minutes) when messages expected \u2192 Stale stream</li> <li> <p>Action: Check server health, verify stream is active</p> </li> <li> <p>UptimeMillis: Connection uptime in milliseconds</p> </li> <li> <p>Info: Use to track connection stability</p> </li> <li> <p>TotalReconnects: Total reconnection attempts</p> </li> <li>Alert: Rapid increase (&gt;10 in 5 minutes) \u2192 Unstable connection</li> <li>Action: Review server stability, check network/firewall</li> </ul>"},{"location":"operations/RUNBOOK/#derived-metrics","title":"Derived Metrics","text":"<ul> <li>LagCount: MessagesReceived - RecordsProduced</li> <li>Alert: &gt; 10000 \u2192 Processing backlog</li> <li> <p>Action: Review Kafka producer performance</p> </li> <li> <p>DropRate: (MessagesDropped / MessagesReceived) * 100</p> </li> <li>Alert: &gt; 1% \u2192 Significant message loss</li> <li>Action: Increase queue size or optimize throughput</li> </ul>"},{"location":"operations/RUNBOOK/#recommended-alerts","title":"Recommended Alerts","text":"<pre><code># Example Prometheus alerting rules\ngroups:\n  - name: grpc_connector\n    rules:\n      - alert: GrpcDisconnected\n        expr: grpc_isConnected == 0\n        for: 2m\n        annotations:\n          summary: \"gRPC connection lost for {{ $labels.connector_name }}\"\n          description: \"Connection to {{ $labels.server }} has been down for 2 minutes\"\n\n      - alert: HighMessageDropRate\n        expr: grpc_DropRate &gt; 1\n        for: 5m\n        annotations:\n          summary: \"High message drop rate for {{ $labels.connector_name }}\"\n          description: \"Dropping {{ $value }}% of messages - queue capacity insufficient\"\n\n      - alert: HighProcessingLag\n        expr: grpc_LagCount &gt; 10000\n        for: 5m\n        annotations:\n          summary: \"High processing lag for {{ $labels.connector_name }}\"\n          description: \"Lag count: {{ $value }} - Kafka throughput issue\"\n\n      - alert: FrequentReconnections\n        expr: increase(grpc_TotalReconnects[5m]) &gt; 10\n        annotations:\n          summary: \"Frequent reconnections for {{ $labels.connector_name }}\"\n          description: \"{{ $value }} reconnections in 5 minutes - unstable connection\"\n\n      - alert: SequenceGapsDetected\n        expr: rate(grpc_sequence_gaps[5m]) &gt; 0\n        annotations:\n          summary: \"Sequence gaps detected for {{ $labels.connector_name }}\"\n          description: \"Data loss detected - investigate queue overflow or network issues\"\n</code></pre>"},{"location":"operations/RUNBOOK/#common-issues","title":"Common Issues","text":""},{"location":"operations/RUNBOOK/#issue-1-connection-keeps-dropping","title":"Issue 1: Connection Keeps Dropping","text":"<p>Symptoms: - <code>IsConnected</code> metric flipping between true/false - <code>TotalReconnects</code> incrementing rapidly - Logs showing \"event=connection_closed\" or \"event=connection_failed\"</p> <p>Root Causes: 1. Network instability 2. gRPC server restarts or issues 3. Keepalive timeout mismatch 4. TLS certificate expiration 5. Firewall/proxy timeout</p> <p>Resolution: <pre><code># Check connector status\ncurl -s http://localhost:8083/connectors/grpc-connector/status | jq .\n\n# Review recent logs\nkubectl logs -l app=kafka-connect --tail=100 | grep \"event=connection\"\n\n# Test gRPC endpoint\ngrpcurl -plaintext &lt;host&gt;:&lt;port&gt; list\n\n# Verify TLS (if enabled)\nopenssl s_client -connect &lt;host&gt;:&lt;port&gt;\n\n# Actions:\n1. Increase grpc.connection.timeout.ms (default: 30000)\n2. Adjust keepalive settings:\n   - grpc.keepalive.time.ms (default: 30000)\n   - grpc.keepalive.timeout.ms (default: 10000)\n3. Verify TLS certificates are valid\n4. Check gRPC server logs for errors\n5. Review network path for issues\n</code></pre></p>"},{"location":"operations/RUNBOOK/#issue-2-high-message-drop-rate","title":"Issue 2: High Message Drop Rate","text":"<p>Symptoms: - <code>DropRate</code> metric &gt; 1% - <code>MessagesDropped</code> incrementing - <code>QueueUtilizationPercent</code> at 100% - Logs showing \"event=queue_full\"</p> <p>Root Causes: 1. Queue capacity too small for message rate 2. Kafka broker throughput bottleneck 3. Kafka producer configuration suboptimal 4. Consumer lag in downstream consumers</p> <p>Resolution: <pre><code># Check queue metrics via JMX\njconsole # Connect and view queue metrics\n\n# Actions:\n1. Increase queue size:\n   grpc.message.queue.size=50000 (default: 10000)\n\n2. Optimize Kafka producer (in connect-distributed.properties):\n   producer.linger.ms=10\n   producer.batch.size=32768\n   producer.compression.type=lz4\n   producer.acks=1\n\n3. Check Kafka broker health:\n   kafka-broker-api-versions --bootstrap-server localhost:9092\n\n4. Monitor topic metrics:\n   kafka-topics --bootstrap-server localhost:9092 --describe --topic &lt;topic&gt;\n\n5. Increase topic partitions if needed:\n   kafka-topics --alter --topic &lt;topic&gt; --partitions 10\n</code></pre></p>"},{"location":"operations/RUNBOOK/#issue-3-no-messages-received","title":"Issue 3: No Messages Received","text":"<p>Symptoms: - <code>MessagesReceived</code> not incrementing - <code>IsConnected</code> = true - No errors in logs</p> <p>Root Causes: 1. gRPC server not sending messages 2. Stream method not implemented correctly 3. Request message filtering out all data 4. Wrong service/method name</p> <p>Resolution: <pre><code># Test gRPC service manually\ngrpcurl -plaintext &lt;host&gt;:&lt;port&gt; &lt;service&gt;/&lt;method&gt;\n\n# With proto descriptor\ngrpcurl -protoset service.desc &lt;host&gt;:&lt;port&gt; &lt;service&gt;/&lt;method&gt;\n\n# With request message\ngrpcurl -d '{\"filter\":\"test\"}' -protoset service.desc &lt;host&gt;:&lt;port&gt; &lt;service&gt;/&lt;method&gt;\n\n# Actions:\n1. Verify gRPC server is actively streaming\n2. Check server logs for issues\n3. Verify service and method names are correct\n4. Test request message format\n5. Check MillisSinceLastMessage metric\n6. Review server-side logs for connection info\n</code></pre></p>"},{"location":"operations/RUNBOOK/#issue-4-processing-lag-building-up","title":"Issue 4: Processing Lag Building Up","text":"<p>Symptoms: - <code>LagCount</code> increasing - <code>QueueSize</code> growing - <code>RecordsProduced</code> not keeping pace with <code>MessagesReceived</code></p> <p>Root Causes: 1. Kafka broker slowness 2. Network issues to Kafka 3. Insufficient topic partitions 4. Producer throughput limitation</p> <p>Resolution: <pre><code># Check Kafka broker metrics\nkafka-run-class kafka.tools.JmxTool \\\n  --object-name kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec \\\n  --jmx-url service:jmx:rmi:///jndi/rmi://localhost:9999/jmxrmi\n\n# Check topic configuration\nkafka-topics --bootstrap-server localhost:9092 --describe --topic &lt;topic&gt;\n\n# Actions:\n1. Increase topic partitions for parallelism\n2. Check Kafka broker disk I/O and network\n3. Monitor Kafka producer metrics\n4. Review connect-distributed.properties producer settings\n5. Consider adding more Kafka brokers\n</code></pre></p>"},{"location":"operations/RUNBOOK/#issue-5-sequence-gaps-detected","title":"Issue 5: Sequence Gaps Detected","text":"<p>Symptoms: - Logs showing \"event=sequence_gap\" - Warnings about missing sequence numbers - Potential data loss</p> <p>Root Causes: 1. Queue overflow (messages dropped) 2. Network packet loss 3. gRPC server skipping sequences 4. Connector restart with offset mismatch</p> <p>Resolution: <pre><code># Check for gap warnings\ngrep \"event=sequence_gap\" $KAFKA_HOME/logs/connect.log | tail -20\n\n# Check queue utilization\n# Monitor QueueUtilizationPercent metric\n\n# Actions:\n1. Increase grpc.message.queue.size if queue was full\n2. Review network stability between connector and gRPC server\n3. Check gRPC server logs for abnormalities\n4. Verify offset management is working correctly\n5. If gaps persist, investigate gRPC server implementation\n</code></pre></p>"},{"location":"operations/RUNBOOK/#performance-tuning","title":"Performance Tuning","text":""},{"location":"operations/RUNBOOK/#queue-sizing","title":"Queue Sizing","text":"<p>Default: 10000 messages</p> <p>Recommendations: - Low-volume, low-latency: 1000-5000 - Medium-volume: 10000-20000 (default) - High-volume (&gt;1000 msg/sec): 50000-100000</p> <p>Trade-offs: - Larger queue = more memory usage, better burst handling - Smaller queue = less memory, more drops under bursts</p>"},{"location":"operations/RUNBOOK/#reconnection-settings","title":"Reconnection Settings","text":"<p>Production Recommendations: <pre><code>grpc.reconnect.enabled=true\ngrpc.reconnect.interval.ms=5000\ngrpc.reconnect.max.attempts=-1  # infinite retries\ngrpc.reconnect.backoff.max.ms=60000\n</code></pre></p> <p>Dev/Test Recommendations: <pre><code>grpc.reconnect.enabled=true\ngrpc.reconnect.interval.ms=1000\ngrpc.reconnect.max.attempts=10\ngrpc.reconnect.backoff.max.ms=10000\n</code></pre></p>"},{"location":"operations/RUNBOOK/#keepalive-settings","title":"Keepalive Settings","text":"<p>Adjust based on network conditions:</p> Network Type Keepalive Time Keepalive Timeout Local network 60000ms 10000ms Cloud (same region) 30000ms 10000ms Cross-region 20000ms 5000ms Unstable network 10000ms 3000ms"},{"location":"operations/RUNBOOK/#message-size-limits","title":"Message Size Limits","text":"<p>Default: 4MB (4194304 bytes)</p> <p>Adjust based on actual message size: <pre><code># For larger messages\ngrpc.max.inbound.message.size=16777216  # 16MB\n\n# For smaller messages (save memory)\ngrpc.max.inbound.message.size=1048576  # 1MB\n</code></pre></p>"},{"location":"operations/RUNBOOK/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/RUNBOOK/#debug-logging","title":"Debug Logging","text":"<p>Enable debug logging for detailed troubleshooting:</p> <pre><code># Connector logging\nlog4j.logger.io.conduktor.connect.grpc=DEBUG\n\n# gRPC Java logging\nlog4j.logger.io.grpc=DEBUG\n\n# Netty (gRPC transport)\nlog4j.logger.io.netty=DEBUG\n</code></pre>"},{"location":"operations/RUNBOOK/#common-log-messages","title":"Common Log Messages","text":"Log Event Severity Meaning Action \"event=streaming_started\" INFO gRPC stream active Normal operation \"event=connection_closed\" INFO Connection closed Reconnection will occur if enabled \"event=connection_failed\" ERROR Connection attempt failed Check server availability, TLS config \"event=queue_full\" WARN Queue overflow Increase queue size \"event=sequence_gap\" WARN Missing sequence number Investigate data loss \"event=session_initialized\" INFO New session started Normal after reconnection"},{"location":"operations/RUNBOOK/#health-check-script","title":"Health Check Script","text":"<pre><code>#!/bin/bash\n# health-check.sh\n\nCONNECTOR_NAME=\"grpc-connector\"\nCONNECT_URL=\"http://localhost:8083\"\n\n# Check connector status\nSTATUS=$(curl -s $CONNECT_URL/connectors/$CONNECTOR_NAME/status | jq -r '.connector.state')\n\nif [ \"$STATUS\" != \"RUNNING\" ]; then\n  echo \"CRITICAL: Connector not running (state: $STATUS)\"\n  exit 2\nfi\n\n# Check task status\nTASK_STATUS=$(curl -s $CONNECT_URL/connectors/$CONNECTOR_NAME/status | jq -r '.tasks[0].state')\n\nif [ \"$TASK_STATUS\" != \"RUNNING\" ]; then\n  echo \"CRITICAL: Task not running (state: $TASK_STATUS)\"\n  exit 2\nfi\n\n# Check JMX metrics (requires jmxterm)\nCONNECTED=$(echo \"get -b io.conduktor.connect.grpc:type=GrpcConnector,name=$CONNECTOR_NAME,server=* IsConnected\" | \\\n  java -jar jmxterm.jar -l localhost:9999 -n)\n\nif [ \"$CONNECTED\" != \"true\" ]; then\n  echo \"WARNING: gRPC not connected\"\n  exit 1\nfi\n\necho \"OK: Connector healthy\"\nexit 0\n</code></pre>"},{"location":"operations/RUNBOOK/#grpc-connection-testing","title":"gRPC Connection Testing","text":"<pre><code># Test plaintext connection\ngrpcurl -plaintext &lt;host&gt;:&lt;port&gt; list\ngrpcurl -plaintext &lt;host&gt;:&lt;port&gt; &lt;service&gt;/&lt;method&gt;\n\n# Test TLS connection\ngrpcurl -cacert ca.crt &lt;host&gt;:&lt;port&gt; list\n\n# Test mTLS connection\ngrpcurl -cacert ca.crt \\\n  -cert client.crt \\\n  -key client.key \\\n  &lt;host&gt;:&lt;port&gt; list\n\n# With proto descriptor\ngrpcurl -protoset service.desc &lt;host&gt;:&lt;port&gt; list\ngrpcurl -protoset service.desc &lt;host&gt;:&lt;port&gt; describe &lt;service&gt;\n</code></pre>"},{"location":"operations/RUNBOOK/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"operations/RUNBOOK/#restart-connector","title":"Restart Connector","text":"<pre><code># Pause connector\ncurl -X PUT http://localhost:8083/connectors/grpc-connector/pause\n\n# Wait for current messages to flush\nsleep 10\n\n# Resume connector\ncurl -X PUT http://localhost:8083/connectors/grpc-connector/resume\n\n# Verify status\ncurl -s http://localhost:8083/connectors/grpc-connector/status | jq .\n</code></pre>"},{"location":"operations/RUNBOOK/#reset-offsets","title":"Reset Offsets","text":"<p>WARNING: This will restart streaming from current position.</p> <pre><code># Delete connector\ncurl -X DELETE http://localhost:8083/connectors/grpc-connector\n\n# Wait for cleanup\nsleep 5\n\n# Recreate connector with fresh configuration\ncurl -X POST http://localhost:8083/connectors \\\n  -H \"Content-Type: application/json\" \\\n  -d @connector-config.json\n</code></pre>"},{"location":"operations/RUNBOOK/#emergency-shutdown","title":"Emergency Shutdown","text":"<p>If connector is misbehaving and needs immediate shutdown:</p> <pre><code># Option 1: Pause connector (graceful)\ncurl -X PUT http://localhost:8083/connectors/grpc-connector/pause\n\n# Option 2: Delete connector (removes from cluster)\ncurl -X DELETE http://localhost:8083/connectors/grpc-connector\n\n# Option 3: Restart Connect worker (nuclear option)\nkubectl delete pod -l app=kafka-connect\n</code></pre>"},{"location":"operations/RUNBOOK/#certificate-renewal","title":"Certificate Renewal","text":"<p>For TLS/mTLS certificate expiration:</p> <pre><code># 1. Update certificate files\ncp new-ca.crt /etc/ssl/certs/ca.crt\ncp new-client.crt /etc/ssl/certs/client.crt\ncp new-client.key /etc/ssl/private/client.key\n\n# 2. Update connector configuration\ncurl -X PUT http://localhost:8083/connectors/grpc-connector/config \\\n  -H \"Content-Type: application/json\" \\\n  -d @updated-config.json\n\n# 3. Connector will restart automatically with new certificates\n</code></pre>"},{"location":"operations/RUNBOOK/#contact-and-escalation","title":"Contact and Escalation","text":"<p>For issues not covered in this runbook:</p> <ol> <li>Review connector logs at DEBUG level</li> <li>Check Kafka Connect worker logs</li> <li>Verify gRPC server health and logs</li> <li>Test gRPC connection with grpcurl</li> <li>Consult project documentation: https://github.com/conduktor/kafka-connect-grpc</li> <li>Open issue with:</li> <li>Connector configuration (sanitized)</li> <li>JMX metrics snapshot</li> <li>Relevant logs (last 1000 lines)</li> <li>gRPC server details</li> <li>Kafka Connect worker version</li> <li>Kafka broker version</li> </ol>"}]}